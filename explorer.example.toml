# user: postgresql database user
# name: postgresql database name
# password: postgresql database password
# fetch_rows: number of rows to fetch from the database when using named cursors
# min_connections: minimum number of connections to create in the database pool
[database]
user = "<user>"
name = "<database>"
password = "<password>"
fetch_rows = 1000
min_connections = 8

# host: IP address of the node pool
# port: RPC port on which the node pool can be reached
# default_timeout: timeout for a socket to receive a request response
[node-pool]
host = "127.0.0.1"
port = 22819
default_timeout = 15

# log_file: specify logging file name
# level_file: log to the file with the specified logging level (debug, info, warning, error or critical)
# level_stdout: log to stdout with the specified logging level (debug, info, warning, error or critical)
[node-pool.log]
log_file = "/path/to/logs/node-pool.log"
level_file = "info"
level_stdout = "info"

# binary: location of the witnet binary
# number: amount of nodes to start, configuration is defined in [nodes.node-x]
# sync_sleep: while synchronizing a node, check its synchonization status every 'sync_sleep' seconds
# no_peers_restart: restart node if we have not found enough peers after 'no_peers_restart' seconds
# outbound_connections: required amount of outbound connections to synchronize a node, this is a setting in each node's toml file
# restart_unsynced_timeout: nodes that are rolling back are unsynced, but may recover, allow this for 'restart_unsynced_timeout' seconds
[node-pool.nodes]
binary = "/path/to/witnet/binary"
number = 2
sync_sleep = 60
no_peers_restart = 3600
outbound_connections = 8
restart_unsynced_timeout = 360

# type: the node type can either be local or remote, local nodes can be restarted automatically, remotes ones cannot
# ip: IP address of the node (always required, local nodes will typically listen on 127.0.0.1)
# port: RPC port of the node (always required)
# config: specify the toml configuration file of the node (only required for locally running nodes)
# master_key: path to the master key of the node if required
# log_file: redirect the output of the node to the specified file (only required for locally running nodes)
[node-pool.nodes.node-1]
type = "local"
ip = "127.0.0.1"
port = 21338
config = "/path/to/node/config/node-1.toml"
master_key = "/path/to/node/key/node-1.key"
log_file = "/path/to/logs/node-1.log"

[node-pool.nodes.node-2]
type = "local"
ip = "127.0.0.1"
port = 22338
config = "/path/to/node/config/node-2.toml"
master_key = "/path/to/node/key/node-2.key"
log_file = "/path/to/logs/node-2.log"

# path: path to explorer directory
# error_retry: timeout before retrying a request that returned an error
# pending_interval: time between querying how many pending requests there are in the network
[explorer]
path = "/home/witnet/explorer"
error_retry = 60
pending_interval = 60

# log_file: specify logging file name
# level_file: log to the file with the specified logging level (debug, info, warning, error or critical)
# level_stdout: log to stdout with the specified logging level (debug, info, warning, error or critical)
[explorer.log]
log_file = "/path/to/logs/explorer.log"
level_file = "info"
level_stdout = "info"

# error_retry: timeout before retrying a request that returned an error
# cache_server: caching is enabled through memcached
[api]
error_retry = 60
cache_server = "memcached"

# log_file: specify logging file name
# level_file: log to the file with the specified logging level (debug, info, warning, error or critical)
# level_stdout: log to stdout with the specified logging level (debug, info, warning, error or critical)
[api.log]
log_file = "/path/to/logs/api.log"
level_file = "info"
level_stdout = "info"

# server: IP address of the running memcached server, defaults to localhost
# user: username for the memcached server
# password: password for the memcached server
# threads: the number of threads to use in a memcached connection pool
# blocking: wait until a connection is free to execute the request
# node_retries: times to retry fetching data from a Witnet node
# plot_directory: directory where to save the plots generated by plotting scripts
[api.caching]
server = "<IP>"
user = "<user>"
password = "<password>"
threads = "<threads>"
blocking = "<blocking>"
node_retries = 5
# note: the cache.py file in the app directory contains a number of hardcoded memcached-specific settings
plot_directory = "/path/to/plots"

# host: IP address of the addresses caching process
# port: RPC port on which the address caching process can be reached
# default_timeout: timeout for a socket to receive a request response
# level_file: log to the file with the specified logging level (debug, info, warning, error or critical)
# level_stdout: log to stdout with the specified logging level (debug, info, warning, error or critical)
# log_file: specify logging file name
# cache_size: the number of tracked addresses for which API call results are updated and cached
# processes: the number of concurrent processes which can be used to query the database for API call results
# views_timeout: timeout after which address views data (value transfers, data requests and blocks) is deleted from the cache
# reputation_timeout: timeout after which reputation helper variable is deleted from the cache
# utxos_timeout: timeout after which utxo data is deleted from the cache
# address_stack_file: file to persist the address stack and load after a restart
# concurrent_request_timeout: timeout before track requests for the same address are processed
[api.caching.scripts.addresses]
host = "127.0.0.1"
port = 22820
default_timeout = 15
level_file = "info"
level_stdout = "info"
log_file = "/path/to/logs/address.log"
cache_size = 100
processes = 4
views_timeout = 86400 # 1 day
reputation_timeout = 3600 # 1 hour
utxos_timeout = 3600 # 1 hour
address_stack_file = "/path/to/address_stack.json"
concurrent_request_timeout = 15

# cron: specify the crontab timing configuration
# level_file: log to the file with the specified logging level (debug, info, warning, error or critical)
# log_file: specify logging file name
# timeout: specify the memcached timeout (in seconds) after which the data is invalidated
[api.caching.scripts.blocks]
cron = "* * * * *"
level_file = "info"
log_file = "/path/to/blocks.log"
timeout = 86400 # 1 day

# cron: specify the crontab timing configuration
# level_file: log to the file with the specified logging level (debug, info, warning, error or critical)
# log_file: specify logging file name
[api.caching.scripts.home_stats]
cron = "* * * * *"
level_file = "info"
log_file = "/path/to/logs/home_stats.log"

# cron: specify the crontab timing configuration
# level_file: log to the file with the specified logging level (debug, info, warning, error or critical)
# log_file: specify logging file name
# node_timeout: overwrite the default node timeout to fetch big amounts of data from a node
# aggregation_epochs: number of epochs for which statistics are aggregated
[api.caching.scripts.network_stats]
cron = "0 * * * *"
level_file = "info"
log_file = "/path/to/logs/network_stats.log"
node_timeout = 60
aggregation_epochs = 1000

# cron: specify the crontab timing configuration
# level_file: log to the file with the specified logging level (debug, info, warning, error or critical)
# log_file: specify logging file name
# timeout: specify the memcached timeout (in seconds) after which the data is invalidated
# cache_time_warning: the caching process will print a warning when the it ran for more than this amount of time (in seconds)
[api.caching.scripts.data_request_reports]
cron = "* * * * *"
level_file = "info"
log_file = "/path/to/logs/data_request_reports.log"
timeout = 86400 # 1 day
cache_time_warning = 40

# cron: specify the crontab timing configuration
# level_file: log to the file with the specified logging level (debug, info, warning, error or critical)
# log_file: specify logging file name
[api.caching.scripts.reputation_list]
cron = "* * * * *"
level_file = "info"
log_file = "/path/to/logs/reputation_list.log"

# cron: specify the crontab timing configuration
# level_file: log to the file with the specified logging level (debug, info, warning, error or critical)
# log_file: specify logging file name
# timeout: specify the memcached timeout (in seconds) after which the data is invalidated
# node_timeout: overwrite the default node timeout to fetch big amounts of data from a node
[api.caching.scripts.balance_list]
cron = "0 * * * *"
level_file = "info"
log_file = "/path/to/logs/balance_list.log"
timeout = 86400 # 1 day
node_timeout = 60

# cron: specify the crontab timing configuration
# level_file: log to the file with the specified logging level (debug, info, warning, error or critical)
# log_file: specify logging file name
[api.caching.scripts.tapi_list]
cron = "*/5 * * * *"
level_file = "info"
log_file = "/path/to/logs/tapi_list.log"

# timeout: configure timeout (in seconds) for the hash view function
[api.caching.views.hash]
timeout = 86400 # 1 day

# timeout: configure timeout (in seconds) for the mempool view function
[api.caching.views.mempool]
timeout = 15

# timeout: configure timeout (in seconds) for the blockchain view function
[api.caching.views.blockchain]
timeout = 15

# timeout: configure timeout (in seconds) for the status view function
[api.caching.views.status]
timeout = 15

# timeout: configure timeout (in seconds) for the priority view function
[api.caching.views.priority]
timeout = 15

# timeout: configure timeout (in seconds) for the network stats view function
[api.caching.views.network_stats]
timeout = 900
